# 人工知能と社会メモ　2016.12.14

### 質問票から

1.  日本でAIを使っている会社
    *   Watson を導入している会社はかなりあるようですが、どうも宣伝のための様にみえます。
    *   日本には、これから紹介していくような、アメリカのAI企業のようなものがほとんどみあたりません。
    *   実は、今のAIブームのはるか以前から、溶鉱炉の制御に[AIを応用したことで有名な日本人技術者の大力さんという方](http://www.mindshift.co.jp/%E6%9C%AA%E5%88%86%E9%A1%9E/2016/09/28/%E6%A0%AA%E5%BC%8F%E4%BC%9A%E7%A4%BE%E5%A4%A2%E7%9C%9F%E3%83%9B%E3%83%BC%E3%83%AB%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E3%82%B9%E3%81%A8%E3%81%AE%E6%A5%AD%E5%8B%99%E6%8F%90%E6%90%BA%E3%81%AB%E9%96%A2/)がいます。
    *   以前、直接にお話したことがありますが、AIやITの持つ意味を非常に良く理解されていて、やはり、応用に結びつくことをできるのには、そういう深い理解が必要なのだと思ったものです。
    *   しかし、今ではAIやITの本当の意味が分かっていない人や企業が大半であるように思います。

### 前回までの資料から

## AIのタイプ

### Deep Learning などのニューラル・ネットワーク

### IBM Watson

アメリカの人気クイズ番組で、チャンピオンを破った、IBMのAIである、Watsonについての解説。集合的・統計的な知や推論という新しい知のパラダイム、膨大な非構造化データの集積やその処理の技術などが、エキスパートシステムと異なるキーポイントだった。

### 東ロボくんプロジェクト

いままで説明してきた、deep learning, IBM Watson は、今回のAIブームの代表的事例だが、日本においては、これとは別に、2011年に始まった「[東ロボくん](https://ja.wikipedia.org/wiki/東ロボくん#cite_note-nhk20161108-2)」というプロジェクトがあり、それがAIブームの火付け役の一つだったといえる。

その具体的目標は、同プロジェクトのサイトによると、次の様である。

*   本プロジェクトの具体的なベンチマークとして、2016年度までに大学入試センター試験で高得点をマークすること、また2021年度に東京大学入試を突破することを目標に研究活動を進めています。

この様なことを解説した所で、シラバスの８つの項目の内の４と６、次の二つの話に移る。ただし、東ロボくんと、IBM Watson の話は解説済みなので、主に４とイライザの話となる：

*   ４．人工知能論：ドレファス・ヴィノグラードのAI不可能論
*   ６．「知能」の意味：イライザ、IBM Watson, 東ロボくんなどを例に

まずは、[人工無脳](https://ja.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%84%A1%E8%84%B3)とも呼ばれる、[イライザ](https://ja.wikipedia.org/wiki/ELIZA)の話から。

#### ここらあたりから今回の資料

### 人工無脳　イライザとドクター

 Wikipedia 日本版で「人工無脳」の項目から、その英語版に飛ぶと、[Chatterbot](https://en.wikipedia.org/wiki/Chatterbot) という項目になる。つまり、チャットするボットという意味である。

つまり、これは、Twitter で広く使われている[ボット](http://twinavi.jp/guide/section/twitter/glossary/ボット（bot）とは)のことなのである。つまり、自動的につぶやく、そういうソフトである。

[グーグルで、「ボット　人間だと思っていた」を検索](https://www.google.co.jp/?gws_rd=ssl#q=ボット　人間だと思っていた)すると面白い結果になる。

AI論のさきがけでもあった、[アラン・チューリング](https://ja.wikipedia.org/wiki/アラン・チューリング)という数学者は、機械が知的かどうかを判定するための[チューリングテスト](https://ja.wikipedia.org/wiki/チューリング・テスト)というものを提唱した。1950年代のことである。

このチューリングテストをもとに考えると、すでに知的機械は存在しているかのようにみえる。

実は、人間と間違えられるボットのような存在は、1960年代から存在していた。

それが[イライザ](https://ja.wikipedia.org/wiki/ELIZA)やドクターと呼ばれる簡単なプログラム。

これは、あたかも精神分析医が話しているかの様な、「素振り」をするソフト。たとえば、これがその「[会話](https://ja.wikipedia.org/wiki/ELIZA#/media/File:GNU_Emacs_ELIZA_example.png)」のひとつ。

受け答えの妙から、相手はかなりインテリジェンスの高い「人」だと誤解させてしまう。

その誤解の度合いは凄くて、ある人などは、本当に自分の問題をイライザに相談しようとして、他の人たちに、部屋からでていき、自分とイライザだけで話させくれと言ったほどだった。

しかし、イライザは実は、人間の質問の中にある、キーワードやパターンを見つけて、作者の[ワイゼンバウム](https://ja.wikipedia.org/wiki/%E3%82%B8%E3%83%A7%E3%82%BB%E3%83%95%E3%83%BB%E3%83%AF%E3%82%A4%E3%82%BC%E3%83%B3%E3%83%90%E3%82%A6%E3%83%A0)が予め決めた答を出力するだけのプログラムであった。

上の「[会話](https://ja.wikipedia.org/wiki/ELIZA#/media/File:GNU_Emacs_ELIZA_example.png)」例のポイントの一つは、Can you elaborate on that? という文。これは「今言ったことの意味を詳しく説明してもらえますか？」ということだが、それは、Okay, I'll do that then. という発言への答だった。

こういう風にユーザが言ったのは、頭痛ならばお医者さんに行ってくださいというイライザの答に、ユーザが正しく反応したから。

しかし、イライザは、それを「理解」することはなく、おそらく、I'll do　という部分に反応して、ユーザが何かをするといったと判断して、こういう発言をするようにプログラムしてあると思われる。

それはユーザには、期待しなかった発言なので、What are you talking about? と答えると、

Why do you say that? という売り言葉に買い言葉のような、無意味な、しかし、日常の会話に良く見られる本題とは関係のないやりとりのパターンに入り込むように作ってある。

つまり、イライザは単なるアルゴリズム、それも非常に単純なアルゴリズムなのだが、ユーザが、ワイゼンバウムの仕掛けた仕組みに陥ってしまい、あたかも、高い知能を持つもののように勝手に誤解してしまうようになっている。

自分の会話を思い出してみて欲しい。知ったかぶりをしたり、苦境をなんとか切り抜けようとする際に、自分も同じような、「話を本筋からそらす」パターンを使っていることに気が付くだろう。

この単純な冗談プログラムが、AIの歴史に大きな貢献をしたのは、人間というものは、こういうパターンで会話をしているのであり、決して、常に論理的な会話をしているのではないことを、誰にでも分かるように視覚化したことにある。

#### 現代版を少し実験

イライザは、まだ、音声認識など夢の時代の1960年代のプログラムだったので、入力も出力も、文字情報だった。

論理的、合理的な問題に論理的、合理的に答える IBM Watson は、出力も、入力も音声で可能だが、同じようなものに、iPhone の [Sir](https://ja.wikipedia.org/wiki/Siri)i がある。

[英語の Wikipedia の Siri の項目](https://en.wikipedia.org/wiki/Siri)で、これが an [intelligent personal assistant](https://en.wikipedia.org/wiki/Intelligent_personal_assistant) and [knowledge navigator](https://en.wikipedia.org/wiki/Knowledge_Navigator) と説明されているように、これは、IBM　Watson　と同じく、論理的、合理的な問題に論理的、合理的に答えるものであることがわかる。違いは、Watson のようなエキスパートシステムと呼ぶべきシステムが、専門的知識を推論もして取り扱うのに比べて、個人のスケジュール帳、電話帳、WEBなどを、殆ど推論なしに扱うことである。しかし、それはデータの範囲と、推論の深さ（一番浅いのは、たとえば名前を入力して、その人の電話番号を探すというような実質検索だけの場合）の違いだけであって、目的は非常に近いものである。

しかし、Siri　は、その登場以来、ちょうど、新聞記者でさえ東ロボ君を擬人化して考える人がいたように、これを真剣にあるいは冗談で擬人化することが多い。たとえば、[Google の Video 検索](https://www.google.co.jp/search?q=Siri+love&oq=Siri+love&aqs=chrome..69i57j69i61l2.11463j0j9&sourceid=chrome&ie=UTF-8#q=Siri+love&tbm=vid)で Siri と love を検索してみる。

また、AIに恋する中年男性というテーマの [Her](https://en.wikipedia.org/wiki/Her_(film)) という映画が作られているほど、こういうテーマは普遍的なものとなっている。

おそらく、こういうことが起きるだろうと、Siri の開発者たちは思ったらしく、Siri には、それを人格とみなす質問がされた場合に、イライザ流に答える冗談回答が数多く組み込まれている。

つまり、Siri は、基本的には、簡易版・個人版 Watson なのだが、それにはイライザ的なものも冗談として組み込まれている。

その内で、有名なのが、これ：　[１](https://matome.naver.jp/odai/2141964764309550001)　[２](https://matome.naver.jp/odai/2137463033842535401)

<a name="modori">これの仕組み</a>も実は簡単で、それは「イライザについ教えてください」のイライザの部分を、別の女性名にしてみたり、「イライザは食べ物ですか」とか<font color="#ff0000">質問</font>してみると、イライザという言葉だけに反応して<font color="#ff0000">答えている</font>らしいことが分かる。[（ここをクリックしてみてください）](#イライザという言葉)

#### チューリングテスト

人工知能研究の先駆の一人とされる英国の数学者アラン・チューリングは、チューリング機械の発明、第二次世界大戦中のドイツの暗号解読（[それをテーマにした映画。](http://wired.jp/special/2015/imitationgame/01/)史実とは大変異なる。娯楽として見ましょう）、などでも有名だが、AIにおいては、ある人工物が、知的かどうかを判断する基準として[チューリングテスト](https://ja.wikipedia.org/wiki/%E3%83%81%E3%83%A5%E3%83%BC%E3%83%AA%E3%83%B3%E3%82%B0%E3%83%BB%E3%83%86%E3%82%B9%E3%83%88)というものを考えたので有名。これは、ある人工物が、AIといえるかどうかを判定する基準ともいわれる。

そのテストは簡単で、人工物を人から、その実体を見られないようにしておいて、会話だけをさせて、人でないと判断されたら、AIだというもの。

しかし、日本語のWIKIPEDIAの[チューリングテスト](https://ja.wikipedia.org/wiki/%E3%83%81%E3%83%A5%E3%83%BC%E3%83%AA%E3%83%B3%E3%82%B0%E3%83%BB%E3%83%86%E3%82%B9%E3%83%88)にイライザなどを証拠として、このテストが妥当性を持たないとする議論がある書かれているように、この方法は、「人間の知性と同じような知性」というものをテストするには、色々な問題を含んでいる。

たとえば、今回の資料の前の方に書いた、「[グーグルで、「ボット　人間だと思っていた」を検索](https://www.google.co.jp/?gws_rd=ssl#q=ボット　人間だと思っていた)すると面白い結果になる」の検索結果からすると、すでにチューリングテストを通過したようなチャット・ロボットが沢山ある様に見える。

しかし、これは、Twitter のチャットに文字数の上限があることを考えると、東ロボくんが模試などで、高い偏差値を獲得したというのと同じような、「環境の制限」の問題があることがわかる。

つまり、Twitter 上の Chatterbot が可能な理由、また、それが人間と誤解されてしまう理由に、文字数の制限、それにより、Twitter の利用され方に一定のパターンが生じるという問題があると思われる。

また、チューリングテストの大きな問題点として、ハッキリと述べられることは少なかったと思われるが、チューリングも、また、彼の後に、これをAIのテストと考えた人たちの、「知というものの把握」が、「論理的・合理的思考」へ大きくバイアスされていたという問題があるものと思われる。

これは、実はAIの開発にも大きな影響を与えたものと言える。ある意味では、第2次ブームまでと、今回のブームの最大の違いは、これを現在のAI開発者たちが認識しているということにあるともいえる。

### ドレイファスとヴィノグラードの反AI論

AIの可能性を信じる研究者たちに対して、その様な方法では、知能など実現できない、と鋭く批判したアメリカの哲学者がいた。それが、アメリカ流のハイデガー解釈でも有名な、UCバークレーの哲学者、

この哲学者は、第一次ブームの時代から、AI学者が取るような方法では、人間の知能・知性には、絶対に到達できないと、哲学的議論を駆使して、批判を続けた。

その批判の書が、[これら](https://ja.wikipedia.org/wiki/%E3%83%92%E3%83%A5%E3%83%BC%E3%83%90%E3%83%BC%E3%83%88%E3%83%BB%E3%83%89%E3%83%AC%E3%82%A4%E3%83%95%E3%82%A1%E3%82%B9#.E8.91.97.E6.9B.B8)。

実は、ドレイファスが、これらの書物で、AIには出来ないと議論した多くのものが、既に実現されていて、現在は、当たり前のようにスマホなどに搭載されている。

しかし、これはドレイファスが全面的に間違えていたという事ではない。実は、ドレイファスのAI不可能論の最大の論拠は、「AI学者たちは、人間の知性というものは、すべて論理的なものだと誤解している」という点だった。

つまり、エキスパートシステムや第5世代コンピュータの様な作り方では、知能は達成できない。人間の多くの知的活動は、たとえば、ルールが完全に形式的に決まっているチェスの場合でさえ、実は上級者になればなるほど、一種の直観やパターン認識的なもので戦略を決めており、こう指すと、相手は、こう指し、という風な手を先まで読むというような方法で、次の手を決めているのではない。だから、チェスの名人のようなものを作るには、論理的方法だけでは無理なのだ、という風なものが、ドレイファスの主張の基本線だった。

チェスでなくて、将棋だが、羽生名人が、それと同じような発言をしていて、直観が先にあり、その正しさを、論理的な手の読みにより検証するのだとかたっている。[このインタビュー](https://www.youtube.com/watch?v=71-sUKJkxEQ)。

ドレイファスのAI批判の背景には、彼の哲学における専門である、ハイデガー哲学、特に、「存在と時間」の哲学があった。

そのハイデガー哲学の「存在と時間」の、特に被投性という考え方を中心にして、やはりAIや自然言語理解の限界について、1980年代中ごろという第二次ブームの最中にAI批判の書物1986. _Understanding Computers and Cognition: A New Foundation for Design_を発表して、大きな波紋を呼んだ人がいる。

それが、AI研究の総本山の一つだった、スタンフォード大学コンピュータ・サイエンス学科教授の[ティム・ウィノグラード](https://ja.wikipedia.org/wiki/%E3%83%86%E3%83%AA%E3%83%BC%E3%83%BB%E3%82%A6%E3%82%A3%E3%83%8E%E3%82%B0%E3%83%A9%E3%83%BC%E3%83%89)という人。

この書物は、AI、特に自然言語処理の分野には、大きな打撃だったといわれる。

実は、この人は、自然言語を使って、仮想的なロボットと会話しながら、積み木を動かすという、ある意味では、世界で最初に、AIの可能性を示したともいえるシステム[SHRDLU](https://ja.wikipedia.org/wiki/SHRDLU)を作ったので有名な人だった。

その当人がAIや自然言語理解の不可能性を論じたのだから、影響は大きかったらしい。

林は、日本の有名な自然言語理解のチームの代表の講演に出席した際、質問の時間に、このウィノグラードの名前を出しただけで、質問を言い終わらない前に、講演者が、あの人のせいで、研究費が来なくなり大変な目にあったと怒り出したことがあった。それくらいインパクトがあったらしい。

この人の限界論は、ドレイファスのものとは、少し違い、社会のような環境を意識したものだった。

すでに Watson などの話から、実は自然言語処理も、大きく進歩していることを見た。

一見、二人の批判は、外れたようにも見えるのだが、実は、逆に二人ともほぼ正しかったということもできる。

実は、第3次ブームの特徴である、人間の直感のような Deep learning のようなアプローチや、Watson の集合知こそが、この二人の言っていた「AIにかけているもの」だったといえる。

つまり、AI研究者は、これら二人の批判などのAI批判にこたえることにより、新しい段階にAIを進化させたといえる。

ここまでて、AIの基本の話を終わりにして、次回からは、林が参加している、経済産業省のシンクタンク、経済産業研究所のプロジェクトで行っている研究の成果を使い、近未来のAIの社会影響について考える。

その大まかな話は、以前みせた、[この講演](http://www.shayashi.jp/20161115tokyoVer20161116.pdf)で示したもの。

これを丁寧かつ具体的に説明していく。  

### Siri は本当は「<font color="#ff0000">質問</font>」に反応しているのでさえない

<a name="イライザという言葉">仕掛けを明かさないために、「現代版を少し実験」の中に書くべきことをここに書いている。</a>

ここにジャンプしてくる前の文章に、「…とが<font color="#ff0000">質問</font>してみると、イライザという言葉だけに反応して<font color="#ff0000">答えている</font>らしいことが分かる」という部分がある。赤字の部分は、明らかに　Siri を擬人化している。

その前の「それは「イライザについ教えてください」のイライザの部分を、別の女性名にしてみたり、「イライザは食べ物ですか」とか<font color="#ff0000">質問</font>してみる」という部分では、音声で入力しているのは「質問」だということを前提にしている。

ところが、実は、単に「イライザ」と言っても、同じ反応が起きる様になっている。

実験！

この実験の前と後とで、みなさんの心の中の　Siri についてのイメージに変化はなかっただろうか？すくなくとも、イライザという言葉が入った文（？）を使った「会話」についてイメージの変化はなかっただろうか？

Watson や、東ロボくんでも、共通する問題があることは、すでに指摘した。

我々は、相手が「知的存在」だと思うと、自然に、それを擬人化して、実際には、そういうことはないのに、それを「人格」「意識」として把握してしまうという傾向を持つ。

将来、[進化心理学](https://ja.wikipedia.org/wiki/%E9%80%B2%E5%8C%96%E5%BF%83%E7%90%86%E5%AD%A6)などの心理学が解明していくことになるだろうが、これは、おそらく人間が社会的存在であるということ、つまり、単独で生きる様にできておらず、社会などの集団で行動し生きていくように進化した生物だからだろうと思われる。人間は、壁のシミなどに、人の顔や姿を見出す傾向があるが(参考[１](https://en.wikipedia.org/wiki/Pareidolia)，[２](https://matome.naver.jp/odai/2138544844879036001)）、これと、おそらく同じ様な現象と思われる。

AIについて考えるとき、その考える主体である、我々に、この様なバイアスがあるということは、常に留意しておかないといけない。

そうしないと、AIというもの、知的人工物、というものの本当の姿を見誤ることになる。すでに、「知的人工物」と書いたところさえ、意味はハッキリしない。

知とはなにか？ある人工物が知性を持つとは、どういうことか？

これについては、チューリングテストというものが知られている。

[戻る](#modori)